_convert_: all  # For omegaconf struct to be converted to python dictionnaries
# classification_preprocessing_dict = {source_class_code_int: target_class_code_int},
# 3: medium vegetation -> vegetation
# 4: high vegetation -> vegetation
# 160: antenna -> lasting_above
# 161: wind_turbines -> lasting_above
# 162: pylon -> lasting_above
# Note: other codes are also mapped to 1 (unclassified) : they were left in this dataset during its creation, and are a minority.
# We do not drop them (i.e. we do not map them to the reserved noise code (65) during training) 
# in order to avoid unintended conflict in production.
classification_preprocessing_dict: {3: 5, 4: 5, 160: 64, 161: 64, 162: 64, 0: 1, 7: 1, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 1, 57: 1, 58: 1, 66: 1, 67: 1, 77: 1, 155: 1, 204: 1}

# classification_dict = {code_int: name_str, ...} and MUST be sorted (increasing order).
classification_dict: {1: "unclassified", 2: "ground", 5: vegetation, 6: "building", 9: water, 17: bridge, 64: lasting_above}

pos_keys: ["X", "Y", "Z"]
features_keys: ["Intensity", "ReturnNumber", "NumberOfReturns"]
color_keys: ["Red", "Green", "Blue", "Infrared"]

# class_weights for the CrossEntropyLoss with format "[[w1,w2,w3...,wk]]" with w_i a float e.g. 1.0
# Balanced CE: arbitrary weights based on heuristic.
# class_weights: [2.5,1.0,1.0,5.0,20.0,20.0,20.0] normalized so they sum to 7 to preserve scale of CELoss
class_weights: [0.25,0.1,0.1,0.5,2.0,2.0,2.0]
# Input and output dims of neural net are dataset dependant:
d_in: 9
num_classes: 7
